{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0aa42d",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Classification Metrics\n",
    "\n",
    "Used when output is categorical (Yes/No, Spam/Not Spam, Disease/No Disease)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfccf9ae",
   "metadata": {},
   "source": [
    "Confusion Matrix (Base of all metrics)\n",
    "\n",
    "\n",
    "|                | Predicted Yes | Predicted No |\n",
    "| -------------- | ------------- | ------------ |\n",
    "| **Actual Yes** | TP            | FN           |\n",
    "| **Actual No**  | FP            | TN           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fda43",
   "metadata": {},
   "source": [
    "TP: True Positive\n",
    "\n",
    "TN: True Negative\n",
    "\n",
    "FP: False Positive\n",
    "\n",
    "FN: False Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108b828",
   "metadata": {},
   "source": [
    " 1. Accuracy\n",
    "\n",
    " Accuracy=TP+TN/TP+TN+FP+FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fac6f",
   "metadata": {},
   "source": [
    "‚úî When to use:\n",
    "\n",
    "Balanced datasets\n",
    "\n",
    "‚ùå Problem:\n",
    "\n",
    "Misleading for imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5beff1d",
   "metadata": {},
   "source": [
    "Example:\n",
    "99 normal, 1 fraud ‚Üí model predicts all normal\n",
    "Accuracy = 99% ‚ùå (but useless)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea648d22",
   "metadata": {},
   "source": [
    "2 . Precision\n",
    "\n",
    "Precision=TP/TP+FP \n",
    "Out of predicted positives , how many are actually correct?\n",
    "\n",
    "Use when :\n",
    "\n",
    "false positives are costly \n",
    "example :spam detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749e124",
   "metadata": {},
   "source": [
    "3.Recall(sensitivity /TPR)\n",
    "\n",
    "Recall=TP/TP+FN \n",
    "\n",
    "out of actual positives ,how many did we catch?\n",
    "Use when:\n",
    "False negatives are costly \n",
    "Example: cancer detection \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8534fda",
   "metadata": {},
   "source": [
    "4.F1-Score \n",
    "F1=2 X precison X Recall/precision +Recall\n",
    "\n",
    "Balance between Precison and Recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc134c4",
   "metadata": {},
   "source": [
    "5.ROC Curve & AUC\n",
    "\n",
    "ROC: TPR vs FPR curve\n",
    "\n",
    "AUC: Area under ROC curve\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "AUC = 1 ‚Üí Perfect model\n",
    "\n",
    "AUC = 0.5 ‚Üí Random guessing\n",
    "\n",
    "‚úî Widely used in binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb50ed",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Regression Metrics\n",
    "\n",
    "used when output is continues (price ,salary , temprature )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99085b8d",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Regression Metrics\n",
    "\n",
    "Used when the output is **continuous** (price, salary, temperature).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Mean Absolute Error (MAE)\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "‚úî Easy to understand  \n",
    "‚ùå Does not penalize large errors strongly  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Mean Squared Error (MSE)\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2\n",
    "$$\n",
    "\n",
    "‚úî Penalizes large errors  \n",
    "‚ùå Units are squared (less intuitive)  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Root Mean Squared Error (RMSE)\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "‚úî Same units as target variable  \n",
    "‚úî Most popular regression metric  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. R¬≤ Score (Coefficient of Determination)\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "$$\n",
    "\n",
    "**Meaning:**\n",
    "- \\( R^2 = 1 \\) ‚Üí Perfect model  \n",
    "- \\( R^2 = 0 \\) ‚Üí No improvement over mean  \n",
    "\n",
    "‚úî Explains how much variance is captured by the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8341e45",
   "metadata": {},
   "source": [
    "üîπ 3Ô∏è‚É£ Clustering Metrics\n",
    "\n",
    "used when no labels exists. \n",
    ". Silhouette Score\n",
    "\n",
    "Range: ‚àí1 to +1\n",
    "\n",
    "Higher = better clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a950dd",
   "metadata": {},
   "source": [
    "2.Davies‚ÄìBouldin Index\n",
    "\n",
    "Lower value = better cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001f289",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ NLP Metrics\n",
    "\n",
    "| Metric     | Use                 |\n",
    "| ---------- | ------------------- |\n",
    "| BLEU       | Machine Translation |\n",
    "| ROUGE      | Text Summarization  |\n",
    "| Perplexity | Language Models     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1457a8",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Business-Oriented Metrics\n",
    "| Metric             | Use Case              |\n",
    "| ------------------ | --------------------- |\n",
    "| Lift               | Marketing models      |\n",
    "| Gain               | Campaign evaluation   |\n",
    "| Cost-based metrics | Real-world ML systems |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f84049",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ Which Metric Should You Use?\n",
    "\n",
    "| Problem                   | Best Metrics               |\n",
    "| ------------------------- | -------------------------- |\n",
    "| Balanced classification   | Accuracy                   |\n",
    "| Imbalanced classification | Precision, Recall, F1, AUC |\n",
    "| Regression                | RMSE, MAE, R¬≤              |\n",
    "| Medical diagnosis         | Recall                     |\n",
    "| Spam/Fraud detection      | Precision + Recall         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d73e8",
   "metadata": {},
   "source": [
    "Key Interview Tip ‚≠ê\n",
    "\n",
    "Never say ‚Äúaccuracy is always best.‚Äù\n",
    "Always justify metric selection with problem context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08ffde",
   "metadata": {},
   "source": [
    "One-Line Summary\n",
    "\n",
    "Performance metrics quantify how well a model predicts, and choosing the correct metric is as important as choosing the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad04079",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
